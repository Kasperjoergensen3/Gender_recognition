{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from preprocessing import get_preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/fold_0_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gender_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m age_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_test,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m gender_test,\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m age_test ) \u001b[39m=\u001b[39m get_preprocessed_dataset(\u001b[39m\"\u001b[39;49m\u001b[39m.../data\u001b[39;49m\u001b[39m\"\u001b[39;49m, n_max \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/NTU/Skole/DLNN/Gender_recognition/preprocessing.py:115\u001b[0m, in \u001b[0;36mget_preprocessed_dataset\u001b[0;34m(path, frontal, n_max, new_size, test_size)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_preprocessed_dataset\u001b[39m(\n\u001b[1;32m    113\u001b[0m     path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m, frontal\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, n_max\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, new_size\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m\n\u001b[1;32m    114\u001b[0m ):\n\u001b[0;32m--> 115\u001b[0m     df \u001b[39m=\u001b[39m get_dataframe(\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m, frontal\u001b[39m=\u001b[39;49mfrontal)\n\u001b[1;32m    116\u001b[0m     ds \u001b[39m=\u001b[39m create_dataset(df, n_max\u001b[39m=\u001b[39mn_max, new_size\u001b[39m=\u001b[39mnew_size)\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m split_dataset(ds, test_size\u001b[39m=\u001b[39mtest_size)\n",
      "File \u001b[0;32m~/Desktop/NTU/Skole/DLNN/Gender_recognition/preprocessing.py:29\u001b[0m, in \u001b[0;36mget_dataframe\u001b[0;34m(path, frontal)\u001b[0m\n\u001b[1;32m     25\u001b[0m     dfs \u001b[39m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m         pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/fold_frontal_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_data.txt\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)\n\u001b[1;32m     27\u001b[0m     ]\n\u001b[1;32m     28\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     dfs \u001b[39m=\u001b[39m [pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/fold_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_data.txt\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)]\n\u001b[1;32m     30\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# selct only the columns we need\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/NTU/Skole/DLNN/Gender_recognition/preprocessing.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m     dfs \u001b[39m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m         pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m/fold_frontal_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_data.txt\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)\n\u001b[1;32m     27\u001b[0m     ]\n\u001b[1;32m     28\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     dfs \u001b[39m=\u001b[39m [pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mpath\u001b[39m}\u001b[39;49;00m\u001b[39m/fold_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m_data.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)]\n\u001b[1;32m     30\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# selct only the columns we need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown engine: \u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m (valid options are \u001b[39m\u001b[39m{\u001b[39;00mmapping\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[39mreturn\u001b[39;00m mapping[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[39m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open_handles(src, kwds)\n\u001b[1;32m     52\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_handles\u001b[39m(\u001b[39mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m    223\u001b[0m         src,\n\u001b[1;32m    224\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    225\u001b[0m         encoding\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    226\u001b[0m         compression\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    227\u001b[0m         memory_map\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    228\u001b[0m         storage_options\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    229\u001b[0m         errors\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    230\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py:701\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    697\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    700\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    702\u001b[0m             handle,\n\u001b[1;32m    703\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    704\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    705\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    706\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    707\u001b[0m         )\n\u001b[1;32m    708\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    710\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/fold_0_data.txt'"
     ]
    }
   ],
   "source": [
    "(\n",
    "X_train,\n",
    "gender_train,\n",
    "age_train,\n",
    "X_test,\n",
    "gender_test,\n",
    "age_test ) = get_preprocessed_dataset(\"/data\", n_max = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create standard CNN network\n",
    "# idea: expand function such that its easy to change the architechture\n",
    "def CNN_classic():\n",
    "    model = keras.Sequential([\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid')], \n",
    "        name = \"CNN_classic\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# function to create the architechture of the multitask network\n",
    "def CNN_multitask(img_size):\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3), name='input')\n",
    "\n",
    "    main_branch = tf.keras.layers.Conv2D(16, 3, padding = \"same\", activation=\"relu\")(inputs)\n",
    "    main_branch = tf.keras.layers.MaxPooling2D()(main_branch)\n",
    "    main_branch = tf.keras.layers.Conv2D(32, 3, padding = \"same\", activation=\"relu\")(main_branch)\n",
    "    main_branch = tf.keras.layers.MaxPooling2D()(main_branch)\n",
    "    main_branch = tf.keras.layers.Conv2D(64, 3, padding = \"same\", activation=\"relu\")(main_branch)\n",
    "    main_branch = tf.keras.layers.Flatten()(main_branch)\n",
    "    main_branch = tf.keras.layers.Dense(128, activation='relu')(main_branch)\n",
    "\n",
    "    task_1_branch = tf.keras.layers.Dense(256, activation='relu')(main_branch)\n",
    "    task_1_branch = tf.keras.layers.Dense(128, activation='relu')(task_1_branch)\n",
    "    task_1_branch = tf.keras.layers.Dense(1, activation='sigmoid', name='gender')(task_1_branch)\n",
    "\n",
    "    task_2_branch = tf.keras.layers.Dense(256, activation='relu')(main_branch)\n",
    "    task_2_branch = tf.keras.layers.Dense(128, activation='relu')(task_2_branch)\n",
    "    task_2_branch = tf.keras.layers.Dense(8, activation='softmax', name='age')(task_2_branch)\n",
    "\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = [task_1_branch, task_2_branch], name = \"Multitask CNN\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# create dict of the data split. tool to train all models in same function\n",
    "def create_data_dict(X_train, y_train, X_test, y_test):\n",
    "    return {\"X_train\": X_train, \"y_train\": y_train, \"X_test\": X_test, \"y_test\": y_test}\n",
    "\n",
    "# fit all the models to their respective datasets\n",
    "# ** More arguments to adjust fitting procedure **\n",
    "def fit_models(model_data, no_epochs, verbose = 0):\n",
    "\n",
    "    histories = {}\n",
    "    for model,data in model_data.items():\n",
    "        print(f\"Training on Model: {model.name}\")\n",
    "        X_train, y_train, X_test, y_test = data.values()\n",
    "        \n",
    "        histories[model.name] = model.fit(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    epochs = no_epochs,\n",
    "                                    verbose = verbose,\n",
    "                                    validation_data = (X_test,y_test))\n",
    "        print()\n",
    "    return histories\n",
    "\n",
    "\n",
    "def compile_model(model, loss, optimizer = 'adam', metrics = ['accuracy']):\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = loss,\n",
    "        metrics = metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN_classic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_classic \u001b[39m=\u001b[39m CNN_classic()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m compile_model(model_classic, keras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Mads/Desktop/NTU/Skole/DLNN/Gender_recognition/models.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model_multitask \u001b[39m=\u001b[39m CNN_multitask(\u001b[39m224\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CNN_classic' is not defined"
     ]
    }
   ],
   "source": [
    "model_classic = CNN_classic()\n",
    "compile_model(model_classic, keras.losses.BinaryCrossentropy())\n",
    "\n",
    "model_multitask = CNN_multitask(224)\n",
    "multitask_loss = {'gender': keras.losses.BinaryCrossentropy(),\n",
    "                'age': keras.losses.SparseCategoricalCrossentropy()}\n",
    "compile_model(model_multitask, multitask_loss)\n",
    "\n",
    "\n",
    "model_data = {}\n",
    "model_data[model_classic] = create_data_dict(X_train, gender_train, X_test, gender_test)\n",
    "model_data[model_multitask] =  create_data_dict(X_train, (gender_train, age_train), X_test, (gender_test, age_test))\n",
    "\n",
    "fit_models(model_data, 5)\n",
    "              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
